{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_xmyQbjypHC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import PIL\n",
        "\n",
        "from custom_dataset import CustomDataset\n",
        "\n",
        "\n",
        "# class CustomDataset(Dataset):\n",
        "#     def __init__(self, image_path_to_class_dict, class_to_number_dict, apply_resize=False):\n",
        "#         super().__init__()\n",
        "#         self.image_path_to_class_dict = image_path_to_class_dict\n",
        "#         self.class_to_number_dict = class_to_number_dict\n",
        "#         self.image_paths = list(self.image_path_to_class_dict.keys())\n",
        "#         self.resize = transforms.Resize((224, 224))  # Resize to 256x256 for ViT input\n",
        "#         self.to_tensor = transforms.ToTensor()  # Converts images to tensor\n",
        "#         self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                               std=[0.229, 0.224, 0.225])  # Standard normalization for ViT\n",
        "#         self.apply_resize = apply_resize\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.image_paths)\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         # Open the image and convert to RGB\n",
        "#         image = PIL.Image.open(self.image_paths[index]).convert('RGB')\n",
        "\n",
        "#         # Apply resize if needed\n",
        "#         if self.apply_resize:\n",
        "#             image = self.resize(image)\n",
        "\n",
        "#         # Convert the image to a PyTorch tensor and normalize\n",
        "#         image = self.to_tensor(image)\n",
        "#         image = self.normalize(image)\n",
        "\n",
        "#         # Get the corresponding label\n",
        "#         class_name = self.image_path_to_class_dict[self.image_paths[index]]\n",
        "#         label = self.class_to_number_dict[class_name]\n",
        "\n",
        "#         # Convert label to tensor\n",
        "#         label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "#         return image, label\n",
        "    \n",
        "#     if __name__ == \"__main__\":\n",
        "#         dataset = CustomDataset([1, 2, 3, 4, 5])\n",
        "#         dataloader = DataLoader(dataset, num_workers=2) \n",
        "#         for batch in dataloader:\n",
        "#             print(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "our_data_simple = ImageFolder(\"train\",\n",
        "                              transform=transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor()]),\n",
        "                              target_transform=None)\n",
        "\n",
        "class_to_number_dict = our_data_simple.class_to_idx\n",
        "\n",
        "print(len(class_to_number_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zlK1HLc8o6cX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import timm\n",
        "from torchvision.models import vit_b_16\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        num_classes = len(class_to_number_dict)\n",
        "        # Load the pre-trained ViT model\n",
        "        self.vit_model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "\n",
        "        # Replace the classification head (final layer) to match the number of classes\n",
        "        self.vit_model.head = nn.Linear(self.vit_model.head.in_features, num_classes)\n",
        "\n",
        "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "        self.vit_model.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the Vision Transformer model\n",
        "        return self.vit_model(x)\n",
        "    \n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAxRS8z-p3Tl",
        "outputId": "4c6fc236-3841-4428-ad17-147b8a1052bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 0.5721306421265409\n",
            "Training Accuracy: 84.31952662721893%\n",
            "Epoch 2/20, Loss: 0.07106021383928286\n",
            "Training Accuracy: 97.84446322907861%\n",
            "Epoch 3/20, Loss: 0.016276222952591204\n",
            "Training Accuracy: 99.57734573119188%\n",
            "Epoch 4/20, Loss: 0.03258788983677388\n",
            "Training Accuracy: 98.94336432797971%\n",
            "Epoch 5/20, Loss: 0.03576240109632144\n",
            "Training Accuracy: 98.94336432797971%\n",
            "Epoch 6/20, Loss: 0.03744843384924319\n",
            "Training Accuracy: 99.07016060862215%\n",
            "Epoch 7/20, Loss: 0.027056057344354387\n",
            "Training Accuracy: 99.19695688926458%\n",
            "Epoch 8/20, Loss: 0.008469022456100336\n",
            "Training Accuracy: 99.87320371935756%\n",
            "Epoch 9/20, Loss: 0.02426118684289159\n",
            "Training Accuracy: 99.15469146238377%\n",
            "Epoch 10/20, Loss: 0.0706212547547939\n",
            "Training Accuracy: 98.22485207100591%\n",
            "Epoch 11/20, Loss: 0.058272374715228135\n",
            "Training Accuracy: 98.47844463229079%\n",
            "Epoch 12/20, Loss: 0.041625676783607214\n",
            "Training Accuracy: 98.73203719357565%\n",
            "Epoch 13/20, Loss: 0.06534790386747871\n",
            "Training Accuracy: 98.35164835164835%\n",
            "Epoch 14/20, Loss: 0.017502013304447\n",
            "Training Accuracy: 99.70414201183432%\n",
            "Epoch 15/20, Loss: 0.011120089298315547\n",
            "Training Accuracy: 99.83093829247676%\n",
            "Epoch 16/20, Loss: 0.004110080424406742\n",
            "Training Accuracy: 99.91546914623838%\n",
            "Epoch 17/20, Loss: 0.0033711073475707373\n",
            "Training Accuracy: 99.87320371935756%\n",
            "Epoch 18/20, Loss: 0.00603712035356423\n",
            "Training Accuracy: 99.78867286559594%\n",
            "Epoch 19/20, Loss: 0.0023422061188014326\n",
            "Training Accuracy: 99.91546914623838%\n",
            "Epoch 20/20, Loss: 0.007635665591806173\n",
            "Training Accuracy: 99.70414201183432%\n",
            "Epoch 20/20, Loss: 0.007635665591806173, Training Accuracy: 99.70414201183432%\n",
            "Validation Accuracy: 95.10135135135135%\n",
            "Best model saved with validation accuracy: 95.10135135135135%\n",
            "final validation accuracy: 95.10135135135135\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# parser = argparse.ArgumentParser(description= \\\n",
        "#                                      'scipt for training of project 2')\n",
        "# parser.add_argument('--cuda', action='store_true', default=False,\n",
        "#                     help='Used when there are cuda installed.')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# training process.\n",
        "def train_net(net, trainloader, valloader):\n",
        "########## ToDo: Your codes goes below #######\n",
        "    val_accuracy = 0\n",
        "    # val_accuracy is the validation accuracy of each epoch. You can save your model base on the best validation accuracy.\n",
        "\n",
        "    # Define the loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(network.parameters(), lr=0.0001)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "\n",
        "    # optimizer = Adam(network.parameters(), lr=0.001)\n",
        "\n",
        "    num_epochs = 20\n",
        "    best_val_acc = 0.0\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(trainloader)}\")\n",
        "        print(f\"Training Accuracy: {100 * correct_train / total_train}%\")\n",
        "\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(trainloader)}, Training Accuracy: {train_accuracy}%\")\n",
        "\n",
        "\n",
        "    # Validation loop\n",
        "    net.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    print(f\"Validation Accuracy: {val_accuracy}%\")\n",
        "\n",
        "    # Save the model if validation accuracy improves\n",
        "    if val_accuracy > best_val_acc:\n",
        "        best_val_acc = val_accuracy\n",
        "        torch.save(net.state_dict(), 'best_model.pth')\n",
        "        print(f\"Best model saved with validation accuracy: {best_val_acc}%\")\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    return best_val_acc\n",
        "    # return val_accuracy\n",
        "\n",
        "##############################################\n",
        "\n",
        "############################################\n",
        "# Transformation definition\n",
        "# NOTE:\n",
        "# Write the train_transform here. We recommend you use\n",
        "# Normalization, RandomCrop and any other transform you think is useful.\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalization\n",
        "])\n",
        "\n",
        "\n",
        "# train_transform = transforms.Compose([\n",
        "#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "#     transforms.RandomHorizontalFlip(), # to be toggled for testing\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "# ])\n",
        "####################################\n",
        "\n",
        "####################################\n",
        "# Define the training dataset and dataloader.\n",
        "# You can make some modifications, e.g. batch_size, adding other hyperparameters, etc.\n",
        "\n",
        "# Folder path containing the dataset (e.g., '../dataset/')\n",
        "root = 'train'  # Replace with the path to your dataset\n",
        "\n",
        "classes = os.listdir(root)\n",
        "\n",
        "!rm -rf /train/.DS_Store\n",
        "\n",
        "# register all images with their corresponding classes\n",
        "image_path_to_class_dict = {}\n",
        "for class_name in classes:\n",
        "  images = os.listdir(os.path.join(root, class_name))\n",
        "  for image in images:\n",
        "    image_path_to_class_dict[os.path.join(root, class_name, image)] = class_name\n",
        "\n",
        "our_data_simple = ImageFolder(root,\n",
        "                              transform=transforms.Compose([transforms.Resize((256,256)), transforms.ToTensor()]),\n",
        "                              target_transform=None)\n",
        "\n",
        "class_to_number_dict = our_data_simple.class_to_idx\n",
        "\n",
        "# Create an instance of the custom dataset\n",
        "custom_dataset = CustomDataset(image_path_to_class_dict, class_to_number_dict, apply_resize=True)\n",
        "\n",
        "# Split the dataset into train and validation sets (80% train, 20% val)\n",
        "train_size = int(0.8 * len(custom_dataset))\n",
        "val_size = len(custom_dataset) - train_size\n",
        "\n",
        "trainset, valset = torch.utils.data.random_split(custom_dataset, [train_size, val_size])\n",
        "\n",
        "\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "#                                          shuffle=True, num_workers=4)\n",
        "# valloader = torch.utils.data.DataLoader(valset, batch_size=32,\n",
        "#                                          shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                         shuffle=True, num_workers=4)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=4)\n",
        "####################################\n",
        "\n",
        "# ==================================\n",
        "# use cuda if called with '--cuda'.\n",
        "\n",
        "network = Network()\n",
        "# if args.cuda:\n",
        "#     network = network.cuda()\n",
        "\n",
        "# network = network.cuda()\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "network = network.to(device)\n",
        "\n",
        "\n",
        "# train and eval your trained network\n",
        "# you have to define your own\n",
        "val_acc = train_net(network, trainloader, valloader)\n",
        "\n",
        "print(\"final validation accuracy:\", val_acc)\n",
        "\n",
        "# ==================================\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
